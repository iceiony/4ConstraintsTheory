\documentclass[
    floatsintext
]{article}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{subcaption}
\usepackage{amsmath}

\hypersetup{colorlinks,urlcolor=blue}
\let \shorttitle \textbf
\begin{document}

\section{Visual Search}

\subsection{Motivation}
\shorttitle{Visual Search}

In optimising our tool positional search, we must determine regions of contact that are likely to be good locations for the objects interaction.
The proposal follows the idea mentioned by \cite{battaglia2013}, in that humans build mental models of objects to allow inference over the physical world.
Human subjects would have an understanding over the geometric constraints of the physical world and of the forces generated by their actions.
For example, subjects performing tool fitting tasks, examine the geometry of objects and stop at likely positions before attempting interaction.  

Tool and object interaction baring high likelihood of success, would satisfy two criteria: 
\begin{enumerate}
\item \textbf{Geometric constraints} of the two objects must be met ( i.e. the shapes of the two objects should adequately fit )
\item \textbf{Contact forces} generated must correspond to the intention of the actions executed 
  (i.e. for a lifting action, the human subject would focus on points of interaction that would permit vertical forces to be applied)
\end{enumerate}

The total space of possible solutions can be reduced by these criteria without a physics simulation (akin mental simulations \cite{osiurak2014}).
The potential of likely solutions can be later verified using a physics engine. 

\subsection{Geometric Constraints}
The geometries of the tool and object must be compatible. In other words, either the active or passive object's geometry must fit within the gaps and edges of its counterpart.
Tighter fits, offer better transfer of energy and control over the movement of the passive object. A good fit would therefore require less manipulation effort.
In the paradigm of 4CT \cite{osiurak2014}, the effort constraint may explain user's preference for one geometric solution over another.

It is not necessary for the whole geometry of objects to fit. 
It is sufficient that the tool have the necessary parts to act as affordance and functional basis (end effector\cite{zhu2015}).
If the functional part matches the gaps of the passive object, then the configuration is likely to achieve the desired effect. 

\subsubsection{Shape Description and Matching Techniques}
We consider techniques of shape similarity in matching object parts.
Shape analysis techniques have traditionally been engaged in image processing and robot vision for detecting and tracking objects of similar features.
The last two decades have provided many approaches for this type of problem \cite{loncaric1998,zhang2004,veltkamp2001,robert2012}.
Fundamentally, the challenge lies in detecting similarity even as objects undergo geometric transformations (i.e. rotation,translation,scaling and shearing).     

\cite{zhang2004} classify shape similarity into contour-based and region-based techniques. These are further divided into structural and global approaches.
These are further divided into structural and global approaches.
A comprehensive list and relations can be found in fig. \ref{fig:shape_similarity}. 

\begin{figure}[hb]
  \centering
  \includegraphics[width=1\textwidth]{./figures/similarity_techniques.png}
  \caption{Classification of shape similarity techniques (reprinted from \cite{zhang2004})}
  \label{fig:shape_similarity}
\end{figure}  

Contour techniques asses shape similarity by extracting features from the edge of detected objects.
In comparison, region techniques work by assessing surface level information such as: colour features, gradient changes and surface medial.
Techniques from both approaches have justification in human perception \cite{chatbri2016}.
Nonetheless, our use case excludes most region-based approaches as tool parts must correspond to shape gaps.
It is hard to consider gaps as having the surface information needed for region-based matching.

In structural approaches, shapes are considered as composed of primitives. In the case of contour techniques, primitives are segments on the boundary of an object.
The organisation of primitives can be linear (feature vector \cite{zhang2004}) or hierarchical (tree like structures\cite{zhu2015}).
Two objects are considered similar when they have the same primitive structures (or features).
In comparison, global approaches make use of shapes as a whole when assessing similarity. 

Both structural and global approaches have justification in human perception \cite{zhang2004}.
Human subjects show a preference for features even when other shape descriptors are available \cite{chatbri2016}.
At the same time, global shape perception seems to precede local feature detection \cite{navon1977}. 

Matching human behaviour requires more insight into human visual perception.
Loncaric \cite{loncaric1998} describes some theories of human visual perception with interest in image processing.
In a tool use scenario, emphasis should be given to theories describing perception as volumetric, such as through the use of generalised cylinders (known as geons \cite{dickinson2014}).
Such insight may better explain human tool performance, but will however remain for future work.    

\subsubsection{Limitations}
As previously remarked, contour based techniques contain promising approaches for solving tool-object matching problems.
It is important to consider some of the limitations of such techniques, especially with regards to human ability. 

Global contour matching techniques are sensitive to occlusion (i.e. part of the object is hidden from the view point by some obstacle).
In such cases, structural approaches are better suited to identify shapes from visible parts.
Human perception is regarded as able to recognise objects even from sparse information or occluded perspective \cite{loncaric1998}.
In solving tool use scenarios, it is important to consider a subject's visual perspective ( point of view ).
The geometry of objects may not be fully visible, hiding the functional parts.

Most shape similarity techniques are tailored to analysing image based information (i.e. 2D projections of a 3D space).
Human perception however also makes use of depth related knowledge.
As tool use encompasses real world geometric constraints, any contour based approach would have to adapt to 3D information ( e.g. point clouds ).
For our scenario, we can simplify the problem of visual analysis by extracting 3D surface point directly from the physics simulator (instead of using 2D projections). 

Additionally, human subjects may attempt tool and object interaction even when parts do not fully match. 
We therefore require a uniform way of assessing the degree of similarity between two contours. 

We next consider a novel and simple approach for assessing object contours.
It avoids most of the problems enumerated above and scales well to multi-dimensional data, whilst also considering human ability.  

\subsection{Novel Surface Similarity}
Contour matching over two dimensional projections is essentially the problem of assessing the similarity of lines.  
When applied to three dimensional data points the task can be considered as measuring similarity of surfaces.  
The following novel technique can be described as a general approach for assessing surface similarity. 
It is based on principal component analysis (PCA) and Pearson's correlation coefficient. 

\subsubsection{2D Case}
At it's core, the technique assumes that points taken over similar surfaces change value in the same direction and at the same rate. 
For example, consider two lines as in figure \ref{fig:similar_lines_A}. Pairs of points taken from each line change Y axis value at the same time. 
I.e. if point 2 on the red line increases, so does the corresponding point of the blue line.   
More so, compared to figure \ref{fig:similar_lines_B}, the first set of lines change value at the same rate over their own Y axis deviation.
A human observer would asses lines in figure \ref{fig:similar_lines_A} to be more similar than lines in \ref{fig:similar_lines_B},
which are more similar than in figure \ref{fig:similar_lines_C}.

\begin{figure}[ht]
  \centering
  \begin{subfigure}{.49\textwidth}
    \includegraphics[width=1\linewidth]{./figures/similar_lines_A.png}
    \caption{Same direction \& rate (different scales)}
    \label{fig:similar_lines_A}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \includegraphics[width=1\linewidth]{./figures/similar_lines_B.png}
    \caption{Same direction but different rates}
    \label{fig:similar_lines_B}
  \end{subfigure}
  \begin{subfigure}{.49\textwidth}
    \includegraphics[width=1\linewidth]{./figures/similar_lines_C.png}
    \caption{Different directions}
    \label{fig:similar_lines_C}
  \end{subfigure}
  \caption{Lines of different similarity. From (a) to (c) shown in decreasing similarity.}
\end{figure}

In a scenario where lines share the same orientation (e.g. angle against the X axis), Pearson's correlation provides an adequate measure of line similarity.
The correlation coefficient measures the extent to which two variables ( $W \& T$ ) can be defined through a linear equation ( $W = a * T + b$ ).
Resulting values are int range of $[-1,+1]$ where :
\begin{itemize}
    \item values close to +1 represent high similarity
    \item values close to 0 represent dissimilarity 
    \item values close to -1 represent high similarity but mirrored (e.g. points are in reverse order) 
\end{itemize}

Lines with complex curvatures can be expressed through series of points in Cartesian space. 
Affine transformations of scaling\eqref{eq:scale} and translation\eqref{eq:translate} produce new points defining lines who's coordinated are linearly related to the original.
Pearson's correlation would therefore return high similarity if two lines are linear transformations of each other.    
\begin{equation}
  \begin{bmatrix}
    a_x & 0   & 0   \\
    0   & a_y & 0   \\
    0   & 0   &   1 \\ 
  \end{bmatrix} 
  *
  \begin{bmatrix}
    x_i \\ y_i \\ 1
  \end{bmatrix} 
  = 
  \begin{bmatrix}
    a_x * x_i \\ a_y * y_i \\ 1  
  \end{bmatrix}
  \label{eq:scale}
\end{equation}


\begin{equation}
  \begin{bmatrix}
    1 & 0 & b_x \\
    0 & 1 & b_y \\
    0 & 0 & 1   \\ 
  \end{bmatrix} 
  *
  \begin{bmatrix}
    x_i \\ y_i \\ 1
  \end{bmatrix} 
  = 
  \begin{bmatrix}
    x_i + b_x \\ y_i + b_y \\ 1  
  \end{bmatrix}
  \label{eq:translate}
\end{equation}

In the case of rotation\eqref{eq:rotate} or shearing\eqref{eq:shear}, the linear relationship between points is lost.
A graphical example of the different transformations can be seen in figure \ref{fig:affine_transform}.

\begin{figure}[hb]
  \centering
  \includegraphics[width=1\textwidth]{./figures/affine_transform.png}
  \caption{Graphical examples of affine transformations}
  \label{fig:affine_transform}
\end{figure}  

\begin{equation}
  \begin{bmatrix}
    cos(\theta)  & -sin(\theta) &   0 \\
    -sin(\theta) & cost(\theta) &   0 \\
    	0   	 &	0       &   1 \\ 
  \end{bmatrix} 
  *
  \begin{bmatrix}
    x_i \\ y_i \\ 1
  \end{bmatrix} 
  = 
  \begin{bmatrix}
    x_i * cos(\theta) - y_i * sin(\theta) \\ x_i * sin(\theta) + y_i * cos(\theta) \\ 1
  \end{bmatrix} 
  \label{eq:rotate}
\end{equation}


\begin{equation}
  \begin{bmatrix}
    1 & h & 0 \\
    0 & 1 & 0 \\
    0 & 0 & 1   \\ 
  \end{bmatrix} 
  *
  \begin{bmatrix}
    x_i \\ y_i \\ 1
  \end{bmatrix} 
  = 
  \begin{bmatrix}
    x_i + h * y_i \\ y_i \\ 1  
  \end{bmatrix}
  \label{eq:shear}
\end{equation}

In a  tool use scenario involving rigid bodies, shearing is not a reasonable transformation. Rotation on the other hand is. 
PCA returns a set of unit vectors that indicate the direction in which data has most variation. 
Rotation angles of two shapes (or lines) can be removed by aligning the shape's principal components to the main X-Y axis.    
As affine rotations preserve variation, the principal vectors rotate by the same angles that figures are rotated (figure \ref{fig:pca_rotation}).  

\begin{figure}[ht]
  \centering
  \includegraphics[width=.5\textwidth]{./figures/pca_rotation.png}
  \caption{First principal component rotating with the figure}
  \label{fig:pca_rotation}
\end{figure}  


\end{document}


